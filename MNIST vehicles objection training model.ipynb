{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "128ace10",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "\n",
    "#이미지 하나씩이라고 생각한다는 전제하야\n",
    "#하나의 이미지를 150*150으로 넣고, rgb니까 3으로 넣어야겠지\n",
    "#그리고 convolutional layer를 거치면 필터링을 하게돼 -> 32개의 서로 다른 이미지들이 생성돼(컬러를 흑백으로 바꾸는 등)\n",
    "#그 다음 필터링에서도 말 그대로 우리가 인스타에서 하는 필터링을 해 이러한 64개의 서로 다른 이미지들을 만들지\n",
    "#결국 제일 저차원의 피처를 추출하게 되는거야\n",
    "\n",
    "\n",
    "model = models.Sequential() #CNN layer 생성\n",
    "model.add(layers.Conv2D(32, (3, 3), activation = 'relu', #3*3 convolutional layer 사용 / 활성화 함수는 relu, input 이미지의 형태:가로150,세로150,RGB값(3)\n",
    "                       input_shape = (150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation = 'relu',))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation = 'relu',))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation = 'relu',))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation = 'relu',))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten()) #64*3*3을 1차원으로 만듦\n",
    "model.add(layers.Dropout(0.5)) #\n",
    "model.add(layers.Dense(512, activation = 'relu')) #\n",
    "model.add(layers.Dense(1, activation = 'sigmoid')) #sigmoid (2진법에 사용됨)\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f4203ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model.compile(loss='binary_crossentropy', #2진법에 사용됨\n",
    "             optimizer = optimizers.SGD(learning_rate=1e-4),\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ed2946",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e51037e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8670 images belonging to 2 classes.\n",
      "Found 9042 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                r'C:\\Users\\Seo\\Desktop\\AI-PARKINGLOT - copy', #트레이닝 이미지 불러오기\n",
    "                target_size = (150, 150), #인풋 이미지 킈기가 150*150이므로 사이즈를 동일하게 설정\n",
    "                batch_size = 32, #5000개의 트레이닝 이미지를 20번에 나눠서 줌 -> 배치 한번에 250개의 이미지가 들어감\n",
    "                class_mode = 'binary') #binary = 이진법\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "                r'C:\\Users\\Seo\\Desktop\\png\\test', #validaiton 이미지 불러오기\n",
    "                target_size = (150, 150),\n",
    "                batch_size = 32, #1000개의 테스트 이미지를 20번에 나눠서 줌 -> 배치 1번에 50개의 이미지 들어감\n",
    "                class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e08ebaf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seo\\AppData\\Local\\Temp\\ipykernel_13424\\2033847891.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 84s 833ms/step - loss: 0.6948 - acc: 0.5109 - val_loss: 0.7073 - val_acc: 0.1125\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 85s 848ms/step - loss: 0.6948 - acc: 0.4938 - val_loss: 0.7067 - val_acc: 0.1138\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 84s 840ms/step - loss: 0.6947 - acc: 0.5088 - val_loss: 0.7063 - val_acc: 0.1094\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 88s 877ms/step - loss: 0.6944 - acc: 0.5128 - val_loss: 0.7053 - val_acc: 0.1231\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6943 - acc: 0.5194"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m samples_per_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msamples_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:2209\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2198\u001b[0m \u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   2199\u001b[0m \n\u001b[0;32m   2200\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   2201\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to use\u001b[39;00m\n\u001b[0;32m   2202\u001b[0m \u001b[38;5;124;03m  this endpoint.\u001b[39;00m\n\u001b[0;32m   2203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2204\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2205\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2206\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2207\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   2208\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m-> 2209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2211\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2221\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:1420\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1407\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[0;32m   1408\u001b[0m       x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m   1409\u001b[0m       y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1418\u001b[0m       model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1419\u001b[0m       steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution)\n\u001b[1;32m-> 1420\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1423\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1425\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1428\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1429\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1430\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1431\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1432\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m   1433\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:1716\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1714\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1715\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 1716\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1717\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1718\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "samples_per_epoch = 100 #epoch 한 번 돌릴때마다 100개의 이미지를 봄\n",
    "\n",
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=samples_per_epoch,\n",
    "        epochs = 50, #훈련 50번 시키기\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdccfa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('All_1.h5') #모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f960bf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label = 'Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label = 'Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'ro', label = 'Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label = 'Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38263464",
   "metadata": {},
   "source": [
    "# 데이터 증식 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae15e390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#2버전은 아래 내용 다 바꿈\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range = 40,\n",
    "        width_shift_range = 0.5,\n",
    "        height_shift_range = 0.5,\n",
    "        shear_range = 0.4,\n",
    "        zoom_range = 0.2,\n",
    "        horizontal_flip = True,\n",
    "        fill_mode = 'nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb84c5e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\Seo\\\\Desktop\\\\AI-PARKINGLOT - copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#fnames = sorted([os.path.join(r'C:\\Users\\Seo\\Desktop\\vehicles_and_non-vechiles\\train\\vehicles', fname) for\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#        fname in os.listdir(r'C:\\Users\\Seo\\Desktop\\vehicles_and_non-vechiles\\train\\vehicles')])\u001b[39;00m\n\u001b[0;32m      8\u001b[0m img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSeo\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAI-PARKINGLOT - copy\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m#fnames[3] # 증식할 이미지 선택\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#이미지 읽고 크기 변경\u001b[39;00m\n\u001b[0;32m     12\u001b[0m x \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mimg_to_array(img) \u001b[38;5;66;03m#(150, 150, 3) 크기의 넘파이 배열로 변환\u001b[39;00m\n\u001b[0;32m     13\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m,) \u001b[38;5;241m+\u001b[39m x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;66;03m#(1,150,150,3) 크기로 변환\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\preprocessing\\image.py:313\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras.utils.load_img\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    278\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras.preprocessing.image.load_img\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_img\u001b[39m(path, grayscale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, color_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrgb\u001b[39m\u001b[38;5;124m'\u001b[39m, target_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    280\u001b[0m              interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    281\u001b[0m   \u001b[38;5;124;03m\"\"\"Loads an image into PIL format.\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \n\u001b[0;32m    283\u001b[0m \u001b[38;5;124;03m  Usage:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;124;03m      ValueError: if interpolation method is not supported.\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 313\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrayscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrayscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:113\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pil_image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not import PIL.Image. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    112\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe use of `load_img` requires PIL.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 113\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    114\u001b[0m     img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(f\u001b[38;5;241m.\u001b[39mread()))\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m color_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrayscale\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    116\u001b[0m         \u001b[38;5;66;03m# if image is not already an 8-bit, 16-bit or 32-bit grayscale image\u001b[39;00m\n\u001b[0;32m    117\u001b[0m         \u001b[38;5;66;03m# convert it to an 8-bit grayscale image.\u001b[39;00m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\Seo\\\\Desktop\\\\AI-PARKINGLOT - copy'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import os, shutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#fnames = sorted([os.path.join(r'C:\\Users\\Seo\\Desktop\\vehicles_and_non-vechiles\\train\\vehicles', fname) for\n",
    "#        fname in os.listdir(r'C:\\Users\\Seo\\Desktop\\vehicles_and_non-vechiles\\train\\vehicles')])\n",
    "    \n",
    "img_path = r'C:\\Users\\Seo\\Desktop\\AI-PARKINGLOT - copy' #fnames[3] # 증식할 이미지 선택\n",
    "\n",
    "img = image.load_img(img_path, target_size=(150, 150)) #이미지 읽고 크기 변경\n",
    "\n",
    "x = image.img_to_array(img) #(150, 150, 3) 크기의 넘파이 배열로 변환\n",
    "x = x.reshape((1,) + x.shape) #(1,150,150,3) 크기로 변환\n",
    "i = 0\n",
    "\n",
    "#랜덤하게 변환된 이미지 배치 생성\n",
    "for batch in datagen.flow(x, batch_size = 1):\n",
    "    plt.figure(i)\n",
    "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
    "    i+=1\n",
    "    if i % 4 == 0:\n",
    "        break;\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "174ad20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#버전 3은 con2D 3,4번째 64 -> 128로 수정\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation = 'relu',\n",
    "                       input_shape = (150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5)) #overfitting을 막기 위해 사용\n",
    "model.add(layers.Dense(512, activation = 'relu')) #히든 레이어\n",
    "model.add(layers.Dense(1, activation = 'sigmoid')) #아웃풋\n",
    "#padding = 'valid', stride = 1 ->default\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = optimizers.RMSprop(learning_rate = 1e-4), #optimizer = 학습속도를 빠르고 안정되게 함\n",
    "             metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d87ca7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9473 images belonging to 2 classes.\n",
      "Found 9042 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "#     rotation_range=20,\n",
    "#     width_shift_range = 0.1,\n",
    "#     height_shift_range = 0.1,\n",
    "#     shear_range = 0.1,\n",
    "#     zoom_range = 0.1,\n",
    "#     horizontal_flip = True,)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        r'C:\\Users\\Seo\\Desktop\\AI-PARKINGLOT - copy',\n",
    "        target_size=(150,150),\n",
    "        batch_size = 32,\n",
    "        class_mode = 'binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        r'C:\\Users\\Seo\\Desktop\\project_source\\png\\test',\n",
    "        target_size=(150,150),\n",
    "        batch_size = 32,\n",
    "        class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5442ab8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seo\\AppData\\Local\\Temp\\ipykernel_1556\\1897907687.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "100/100 [==============================] - 124s 1s/step - loss: 0.4299 - acc: 0.8475 - val_loss: 0.4257 - val_acc: 0.8906\n",
      "Epoch 2/200\n",
      "100/100 [==============================] - 132s 1s/step - loss: 0.3428 - acc: 0.8596 - val_loss: 0.3814 - val_acc: 0.9094\n",
      "Epoch 3/200\n",
      "100/100 [==============================] - 136s 1s/step - loss: 0.2696 - acc: 0.8809 - val_loss: 0.6706 - val_acc: 0.8637\n",
      "Epoch 4/200\n",
      "100/100 [==============================] - 131s 1s/step - loss: 0.2378 - acc: 0.9041 - val_loss: 0.7114 - val_acc: 0.8213\n",
      "Epoch 5/200\n",
      "100/100 [==============================] - 122s 1s/step - loss: 0.2106 - acc: 0.9120 - val_loss: 0.8973 - val_acc: 0.8481\n",
      "Epoch 6/200\n",
      "100/100 [==============================] - 116s 1s/step - loss: 0.1957 - acc: 0.9206 - val_loss: 0.8298 - val_acc: 0.8750\n",
      "Epoch 7/200\n",
      "100/100 [==============================] - 107s 1s/step - loss: 0.1761 - acc: 0.9272 - val_loss: 0.8888 - val_acc: 0.8106\n",
      "Epoch 8/200\n",
      "100/100 [==============================] - 105s 1s/step - loss: 0.1658 - acc: 0.9325 - val_loss: 0.8443 - val_acc: 0.8381\n",
      "Epoch 9/200\n",
      "100/100 [==============================] - 106s 1s/step - loss: 0.1624 - acc: 0.9356 - val_loss: 0.8607 - val_acc: 0.8850\n",
      "Epoch 10/200\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.1442 - acc: 0.9481 - val_loss: 0.8981 - val_acc: 0.8694\n",
      "Epoch 11/200\n",
      "100/100 [==============================] - 109s 1s/step - loss: 0.1527 - acc: 0.9426 - val_loss: 1.1200 - val_acc: 0.8875\n",
      "Epoch 12/200\n",
      "100/100 [==============================] - 101s 1s/step - loss: 0.1350 - acc: 0.9444 - val_loss: 1.3042 - val_acc: 0.7769\n",
      "Epoch 13/200\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.1387 - acc: 0.9463 - val_loss: 1.1195 - val_acc: 0.7688\n",
      "Epoch 14/200\n",
      "100/100 [==============================] - 101s 1s/step - loss: 0.1196 - acc: 0.9550 - val_loss: 1.1409 - val_acc: 0.7862\n",
      "Epoch 15/200\n",
      "100/100 [==============================] - 100s 1s/step - loss: 0.1247 - acc: 0.9520 - val_loss: 1.6800 - val_acc: 0.6131\n",
      "Epoch 16/200\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.1121 - acc: 0.9577 - val_loss: 0.7885 - val_acc: 0.8969\n",
      "Epoch 17/200\n",
      "100/100 [==============================] - 100s 999ms/step - loss: 0.1096 - acc: 0.9574 - val_loss: 1.2213 - val_acc: 0.7206\n",
      "Epoch 18/200\n",
      "100/100 [==============================] - 100s 1s/step - loss: 0.0977 - acc: 0.9662 - val_loss: 1.1495 - val_acc: 0.8375\n",
      "Epoch 19/200\n",
      "100/100 [==============================] - 109s 1s/step - loss: 0.1069 - acc: 0.9634 - val_loss: 1.3444 - val_acc: 0.7688\n",
      "Epoch 20/200\n",
      "100/100 [==============================] - 100s 1s/step - loss: 0.1055 - acc: 0.9637 - val_loss: 1.1824 - val_acc: 0.7688\n",
      "Epoch 21/200\n",
      "100/100 [==============================] - 100s 1s/step - loss: 0.1006 - acc: 0.9659 - val_loss: 1.5304 - val_acc: 0.7519\n",
      "Epoch 22/200\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.0923 - acc: 0.9675 - val_loss: 1.2534 - val_acc: 0.7219\n",
      "Epoch 23/200\n",
      "100/100 [==============================] - 101s 1s/step - loss: 0.0843 - acc: 0.9688 - val_loss: 1.4106 - val_acc: 0.7069\n",
      "Epoch 24/200\n",
      "100/100 [==============================] - 100s 999ms/step - loss: 0.0797 - acc: 0.9735 - val_loss: 1.4884 - val_acc: 0.7069\n",
      "Epoch 25/200\n",
      "100/100 [==============================] - 101s 1s/step - loss: 0.0794 - acc: 0.9697 - val_loss: 1.1089 - val_acc: 0.8294\n",
      "Epoch 26/200\n",
      "100/100 [==============================] - 104s 1s/step - loss: 0.0787 - acc: 0.9713 - val_loss: 1.0196 - val_acc: 0.8637\n",
      "Epoch 27/200\n",
      "100/100 [==============================] - 107s 1s/step - loss: 0.0659 - acc: 0.9744 - val_loss: 1.3810 - val_acc: 0.8388\n",
      "Epoch 28/200\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.0932 - acc: 0.9678 - val_loss: 1.1530 - val_acc: 0.8388\n",
      "Epoch 29/200\n",
      "100/100 [==============================] - 113s 1s/step - loss: 0.0819 - acc: 0.9700 - val_loss: 1.2149 - val_acc: 0.8444\n",
      "Epoch 30/200\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.0694 - acc: 0.9734 - val_loss: 1.3366 - val_acc: 0.8125\n",
      "Epoch 31/200\n",
      "100/100 [==============================] - 99s 994ms/step - loss: 0.0715 - acc: 0.9748 - val_loss: 1.4862 - val_acc: 0.8244\n",
      "Epoch 32/200\n",
      "100/100 [==============================] - 101s 1s/step - loss: 0.0623 - acc: 0.9757 - val_loss: 1.1848 - val_acc: 0.8519\n",
      "Epoch 33/200\n",
      "100/100 [==============================] - 100s 1s/step - loss: 0.0763 - acc: 0.9741 - val_loss: 1.1835 - val_acc: 0.7775\n",
      "Epoch 34/200\n",
      "100/100 [==============================] - 101s 1s/step - loss: 0.0744 - acc: 0.9744 - val_loss: 1.7192 - val_acc: 0.7044\n",
      "Epoch 35/200\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.0706 - acc: 0.9763 - val_loss: 1.2389 - val_acc: 0.7169\n",
      "Epoch 36/200\n",
      "100/100 [==============================] - 101s 1s/step - loss: 0.0645 - acc: 0.9750 - val_loss: 1.7535 - val_acc: 0.7956\n",
      "Epoch 37/200\n",
      "100/100 [==============================] - 100s 1s/step - loss: 0.0646 - acc: 0.9800 - val_loss: 1.3807 - val_acc: 0.7962\n",
      "Epoch 38/200\n",
      "100/100 [==============================] - 100s 998ms/step - loss: 0.0633 - acc: 0.9757 - val_loss: 1.3595 - val_acc: 0.7631\n",
      "Epoch 39/200\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.0658 - acc: 0.9776 - val_loss: 1.3234 - val_acc: 0.8550\n",
      "Epoch 40/200\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.0689 - acc: 0.9772 - val_loss: 1.6720 - val_acc: 0.6856\n",
      "Epoch 41/200\n",
      "100/100 [==============================] - 101s 1s/step - loss: 0.0545 - acc: 0.9781 - val_loss: 1.7222 - val_acc: 0.8231\n",
      "Epoch 42/200\n",
      "100/100 [==============================] - 101s 1s/step - loss: 0.0571 - acc: 0.9794 - val_loss: 1.3664 - val_acc: 0.7969\n",
      "Epoch 43/200\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.0508 - acc: 0.9844 - val_loss: 1.7833 - val_acc: 0.7875\n",
      "Epoch 44/200\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.0455 - acc: 0.9816 - val_loss: 1.6593 - val_acc: 0.8188\n",
      "Epoch 45/200\n",
      "100/100 [==============================] - 101s 1s/step - loss: 0.0543 - acc: 0.9825 - val_loss: 2.1693 - val_acc: 0.6425\n",
      "Epoch 46/200\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.0506 - acc: 0.9812 - val_loss: 1.9489 - val_acc: 0.7575\n",
      "Epoch 47/200\n",
      "100/100 [==============================] - 101s 1s/step - loss: 0.0455 - acc: 0.9850 - val_loss: 1.7186 - val_acc: 0.8081\n",
      "Epoch 48/200\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.0472 - acc: 0.9820 - val_loss: 1.8622 - val_acc: 0.7081\n",
      "Epoch 49/200\n",
      "100/100 [==============================] - 101s 1s/step - loss: 0.0565 - acc: 0.9781 - val_loss: 1.3326 - val_acc: 0.8294\n",
      "Epoch 50/200\n",
      "100/100 [==============================] - 100s 1s/step - loss: 0.0497 - acc: 0.9858 - val_loss: 1.9109 - val_acc: 0.7294\n",
      "Epoch 51/200\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.0490 - acc: 0.9836 - val_loss: 1.9330 - val_acc: 0.8213\n",
      "Epoch 52/200\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.0426 - acc: 0.9845 - val_loss: 2.0236 - val_acc: 0.7419\n",
      "Epoch 53/200\n",
      "100/100 [==============================] - 117s 1s/step - loss: 0.0443 - acc: 0.9849 - val_loss: 2.4871 - val_acc: 0.7344\n",
      "Epoch 54/200\n",
      "100/100 [==============================] - 125s 1s/step - loss: 0.0424 - acc: 0.9866 - val_loss: 1.9929 - val_acc: 0.7194\n",
      "Epoch 55/200\n",
      "100/100 [==============================] - 111s 1s/step - loss: 0.0437 - acc: 0.9866 - val_loss: 2.6357 - val_acc: 0.6069\n",
      "Epoch 56/200\n",
      "100/100 [==============================] - 100s 1s/step - loss: 0.0520 - acc: 0.9817 - val_loss: 1.9444 - val_acc: 0.7356\n",
      "Epoch 57/200\n",
      "100/100 [==============================] - 101s 1s/step - loss: 0.0368 - acc: 0.9891 - val_loss: 1.9963 - val_acc: 0.8163\n",
      "Epoch 58/200\n",
      "100/100 [==============================] - 105s 1s/step - loss: 0.0470 - acc: 0.9830 - val_loss: 2.1854 - val_acc: 0.8025\n",
      "Epoch 59/200\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.0376 - acc: 0.9878 - val_loss: 2.4832 - val_acc: 0.6737\n",
      "Epoch 60/200\n",
      "100/100 [==============================] - 104s 1s/step - loss: 0.0454 - acc: 0.9866 - val_loss: 1.9295 - val_acc: 0.7444\n",
      "Epoch 61/200\n",
      "100/100 [==============================] - 115s 1s/step - loss: 0.0335 - acc: 0.9883 - val_loss: 1.4678 - val_acc: 0.8469\n",
      "Epoch 62/200\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.0438 - acc: 0.9853 - val_loss: 1.5410 - val_acc: 0.7437\n",
      "Epoch 63/200\n",
      "100/100 [==============================] - 104s 1s/step - loss: 0.0468 - acc: 0.9861 - val_loss: 1.9399 - val_acc: 0.7150\n",
      "Epoch 64/200\n",
      "100/100 [==============================] - 107s 1s/step - loss: 0.0294 - acc: 0.9887 - val_loss: 1.8763 - val_acc: 0.7812\n",
      "Epoch 65/200\n",
      "100/100 [==============================] - 105s 1s/step - loss: 0.0353 - acc: 0.9862 - val_loss: 2.4762 - val_acc: 0.8012\n",
      "Epoch 66/200\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.0384 - acc: 0.9847 - val_loss: 1.8200 - val_acc: 0.8363\n",
      "Epoch 67/200\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.0424 - acc: 0.9842 - val_loss: 1.8539 - val_acc: 0.7862\n",
      "Epoch 68/200\n",
      "100/100 [==============================] - 98s 986ms/step - loss: 0.0356 - acc: 0.9861 - val_loss: 2.6162 - val_acc: 0.6194\n",
      "Epoch 69/200\n",
      "100/100 [==============================] - 99s 991ms/step - loss: 0.0368 - acc: 0.9884 - val_loss: 2.4460 - val_acc: 0.7138\n",
      "Epoch 70/200\n",
      "100/100 [==============================] - 100s 1s/step - loss: 0.0306 - acc: 0.9897 - val_loss: 2.1904 - val_acc: 0.8375\n",
      "Epoch 71/200\n",
      "100/100 [==============================] - 98s 982ms/step - loss: 0.0342 - acc: 0.9896 - val_loss: 2.3487 - val_acc: 0.7169\n",
      "Epoch 72/200\n",
      "100/100 [==============================] - 98s 980ms/step - loss: 0.0341 - acc: 0.9875 - val_loss: 2.0023 - val_acc: 0.8456\n",
      "Epoch 73/200\n",
      "100/100 [==============================] - 98s 978ms/step - loss: 0.0390 - acc: 0.9875 - val_loss: 1.7465 - val_acc: 0.6844\n",
      "Epoch 74/200\n",
      "100/100 [==============================] - 98s 986ms/step - loss: 0.0303 - acc: 0.9896 - val_loss: 1.9970 - val_acc: 0.7550\n",
      "Epoch 75/200\n",
      "100/100 [==============================] - 98s 987ms/step - loss: 0.0337 - acc: 0.9894 - val_loss: 1.2867 - val_acc: 0.8737\n",
      "Epoch 76/200\n",
      "100/100 [==============================] - 97s 970ms/step - loss: 0.0336 - acc: 0.9867 - val_loss: 2.7263 - val_acc: 0.6281\n",
      "Epoch 77/200\n",
      "100/100 [==============================] - 98s 980ms/step - loss: 0.0275 - acc: 0.9894 - val_loss: 2.0670 - val_acc: 0.7487\n",
      "Epoch 78/200\n",
      "100/100 [==============================] - 98s 978ms/step - loss: 0.0287 - acc: 0.9906 - val_loss: 1.8637 - val_acc: 0.8263\n",
      "Epoch 79/200\n",
      "100/100 [==============================] - 97s 973ms/step - loss: 0.0275 - acc: 0.9915 - val_loss: 2.3175 - val_acc: 0.7469\n",
      "Epoch 80/200\n",
      "100/100 [==============================] - 97s 971ms/step - loss: 0.0276 - acc: 0.9912 - val_loss: 2.4530 - val_acc: 0.7806\n",
      "Epoch 81/200\n",
      "100/100 [==============================] - 96s 966ms/step - loss: 0.0255 - acc: 0.9905 - val_loss: 2.7372 - val_acc: 0.6156\n",
      "Epoch 82/200\n",
      "100/100 [==============================] - 98s 978ms/step - loss: 0.0359 - acc: 0.9874 - val_loss: 2.5159 - val_acc: 0.6694\n",
      "Epoch 83/200\n",
      "100/100 [==============================] - 98s 982ms/step - loss: 0.0323 - acc: 0.9906 - val_loss: 2.4847 - val_acc: 0.7119\n",
      "Epoch 84/200\n",
      "100/100 [==============================] - 99s 988ms/step - loss: 0.0329 - acc: 0.9906 - val_loss: 2.5111 - val_acc: 0.7281\n",
      "Epoch 85/200\n",
      "100/100 [==============================] - 97s 968ms/step - loss: 0.0263 - acc: 0.9915 - val_loss: 2.1806 - val_acc: 0.7588\n",
      "Epoch 86/200\n",
      "100/100 [==============================] - 99s 989ms/step - loss: 0.0257 - acc: 0.9909 - val_loss: 2.6662 - val_acc: 0.6369\n",
      "Epoch 87/200\n",
      "100/100 [==============================] - 98s 978ms/step - loss: 0.0330 - acc: 0.9894 - val_loss: 2.8298 - val_acc: 0.7275\n",
      "Epoch 88/200\n",
      "100/100 [==============================] - 97s 975ms/step - loss: 0.0239 - acc: 0.9922 - val_loss: 2.4595 - val_acc: 0.7206\n",
      "Epoch 89/200\n",
      "100/100 [==============================] - 97s 970ms/step - loss: 0.0319 - acc: 0.9893 - val_loss: 2.4323 - val_acc: 0.8006\n",
      "Epoch 90/200\n",
      "100/100 [==============================] - 101s 1s/step - loss: 0.0283 - acc: 0.9944 - val_loss: 2.6861 - val_acc: 0.6900\n",
      "Epoch 91/200\n",
      "100/100 [==============================] - 98s 979ms/step - loss: 0.0341 - acc: 0.9884 - val_loss: 2.5965 - val_acc: 0.6525\n",
      "Epoch 92/200\n",
      "100/100 [==============================] - 97s 967ms/step - loss: 0.0246 - acc: 0.9918 - val_loss: 2.4348 - val_acc: 0.6662\n",
      "Epoch 93/200\n",
      "100/100 [==============================] - 96s 964ms/step - loss: 0.0203 - acc: 0.9927 - val_loss: 2.5903 - val_acc: 0.7006\n",
      "Epoch 94/200\n",
      "100/100 [==============================] - 97s 975ms/step - loss: 0.0211 - acc: 0.9925 - val_loss: 2.1150 - val_acc: 0.7181\n",
      "Epoch 95/200\n",
      "100/100 [==============================] - 97s 971ms/step - loss: 0.0207 - acc: 0.9919 - val_loss: 2.6018 - val_acc: 0.7369\n",
      "Epoch 96/200\n",
      "100/100 [==============================] - 104s 1s/step - loss: 0.0177 - acc: 0.9919 - val_loss: 2.9670 - val_acc: 0.7550\n",
      "Epoch 97/200\n",
      "100/100 [==============================] - 105s 1s/step - loss: 0.0274 - acc: 0.9903 - val_loss: 2.1671 - val_acc: 0.7812\n",
      "Epoch 98/200\n",
      "100/100 [==============================] - 104s 1s/step - loss: 0.0211 - acc: 0.9928 - val_loss: 2.6455 - val_acc: 0.7294\n",
      "Epoch 99/200\n",
      "100/100 [==============================] - 106s 1s/step - loss: 0.0233 - acc: 0.9937 - val_loss: 4.1591 - val_acc: 0.5169\n",
      "Epoch 100/200\n",
      "100/100 [==============================] - 106s 1s/step - loss: 0.0238 - acc: 0.9924 - val_loss: 3.0143 - val_acc: 0.6569\n",
      "Epoch 101/200\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.0239 - acc: 0.9912 - val_loss: 2.3118 - val_acc: 0.7500\n",
      "Epoch 102/200\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.0150 - acc: 0.9924 - val_loss: 3.2894 - val_acc: 0.7869\n",
      "Epoch 103/200\n",
      "100/100 [==============================] - 100s 997ms/step - loss: 0.0246 - acc: 0.9925 - val_loss: 2.7257 - val_acc: 0.7156\n",
      "Epoch 104/200\n",
      "100/100 [==============================] - 98s 979ms/step - loss: 0.0237 - acc: 0.9927 - val_loss: 1.8457 - val_acc: 0.8425\n",
      "Epoch 105/200\n",
      "100/100 [==============================] - 98s 981ms/step - loss: 0.0282 - acc: 0.9903 - val_loss: 2.6902 - val_acc: 0.7894\n",
      "Epoch 106/200\n",
      "100/100 [==============================] - 98s 979ms/step - loss: 0.0192 - acc: 0.9915 - val_loss: 2.4523 - val_acc: 0.7975\n",
      "Epoch 107/200\n",
      "100/100 [==============================] - 101s 1s/step - loss: 0.0267 - acc: 0.9919 - val_loss: 2.3030 - val_acc: 0.8338\n",
      "Epoch 108/200\n",
      "100/100 [==============================] - 100s 997ms/step - loss: 0.0194 - acc: 0.9944 - val_loss: 2.5803 - val_acc: 0.7800\n",
      "Epoch 109/200\n",
      "100/100 [==============================] - 97s 968ms/step - loss: 0.0200 - acc: 0.9927 - val_loss: 2.5044 - val_acc: 0.7650\n",
      "Epoch 110/200\n",
      "100/100 [==============================] - 98s 983ms/step - loss: 0.0236 - acc: 0.9922 - val_loss: 2.6079 - val_acc: 0.7475\n",
      "Epoch 111/200\n",
      "100/100 [==============================] - 98s 983ms/step - loss: 0.0147 - acc: 0.9937 - val_loss: 2.6750 - val_acc: 0.7325\n",
      "Epoch 112/200\n",
      "100/100 [==============================] - 98s 984ms/step - loss: 0.0173 - acc: 0.9941 - val_loss: 2.8621 - val_acc: 0.6988\n",
      "Epoch 113/200\n",
      "100/100 [==============================] - 97s 973ms/step - loss: 0.0185 - acc: 0.9931 - val_loss: 2.9191 - val_acc: 0.6756\n",
      "Epoch 114/200\n",
      "100/100 [==============================] - 98s 977ms/step - loss: 0.0226 - acc: 0.9950 - val_loss: 2.8961 - val_acc: 0.7681\n",
      "Epoch 115/200\n",
      "100/100 [==============================] - 98s 983ms/step - loss: 0.0278 - acc: 0.9912 - val_loss: 2.6890 - val_acc: 0.7675\n",
      "Epoch 116/200\n",
      "100/100 [==============================] - 98s 979ms/step - loss: 0.0177 - acc: 0.9941 - val_loss: 2.8148 - val_acc: 0.7544\n",
      "Epoch 117/200\n",
      "100/100 [==============================] - 98s 980ms/step - loss: 0.0227 - acc: 0.9947 - val_loss: 3.1722 - val_acc: 0.7025\n",
      "Epoch 118/200\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.0259 - acc: 0.9922 - val_loss: 2.4931 - val_acc: 0.8138\n",
      "Epoch 119/200\n",
      "100/100 [==============================] - 98s 980ms/step - loss: 0.0144 - acc: 0.9924 - val_loss: 2.7219 - val_acc: 0.7656\n",
      "Epoch 120/200\n",
      "100/100 [==============================] - 98s 986ms/step - loss: 0.0125 - acc: 0.9959 - val_loss: 3.4943 - val_acc: 0.6525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/200\n",
      "100/100 [==============================] - 99s 988ms/step - loss: 0.0135 - acc: 0.9937 - val_loss: 2.8745 - val_acc: 0.8037\n",
      "Epoch 122/200\n",
      "100/100 [==============================] - 97s 976ms/step - loss: 0.0175 - acc: 0.9943 - val_loss: 3.6546 - val_acc: 0.7600\n",
      "Epoch 123/200\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.0152 - acc: 0.9950 - val_loss: 3.1851 - val_acc: 0.7669\n",
      "Epoch 124/200\n",
      "100/100 [==============================] - 101s 1s/step - loss: 0.0128 - acc: 0.9953 - val_loss: 3.0797 - val_acc: 0.7669\n",
      "Epoch 125/200\n",
      "100/100 [==============================] - 99s 995ms/step - loss: 0.0214 - acc: 0.9928 - val_loss: 3.0179 - val_acc: 0.5913\n",
      "Epoch 126/200\n",
      "100/100 [==============================] - 99s 993ms/step - loss: 0.0178 - acc: 0.9937 - val_loss: 2.8293 - val_acc: 0.7862\n",
      "Epoch 127/200\n",
      "100/100 [==============================] - 99s 994ms/step - loss: 0.0105 - acc: 0.9965 - val_loss: 2.9831 - val_acc: 0.8156\n",
      "Epoch 128/200\n",
      "100/100 [==============================] - 99s 987ms/step - loss: 0.0130 - acc: 0.9953 - val_loss: 3.2977 - val_acc: 0.6812\n",
      "Epoch 129/200\n",
      "100/100 [==============================] - 98s 978ms/step - loss: 0.0219 - acc: 0.9931 - val_loss: 2.9151 - val_acc: 0.6844\n",
      "Epoch 130/200\n",
      "100/100 [==============================] - 98s 984ms/step - loss: 0.0094 - acc: 0.9966 - val_loss: 2.8033 - val_acc: 0.8550\n",
      "Epoch 131/200\n",
      "100/100 [==============================] - 97s 973ms/step - loss: 0.0187 - acc: 0.9950 - val_loss: 3.5048 - val_acc: 0.6050\n",
      "Epoch 132/200\n",
      "100/100 [==============================] - 96s 965ms/step - loss: 0.0237 - acc: 0.9937 - val_loss: 3.1025 - val_acc: 0.6931\n",
      "Epoch 133/200\n",
      "100/100 [==============================] - 98s 982ms/step - loss: 0.0152 - acc: 0.9947 - val_loss: 2.6533 - val_acc: 0.7462\n",
      "Epoch 134/200\n",
      "100/100 [==============================] - 98s 984ms/step - loss: 0.0181 - acc: 0.9937 - val_loss: 3.6391 - val_acc: 0.6913\n",
      "Epoch 135/200\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.0185 - acc: 0.9962 - val_loss: 2.1938 - val_acc: 0.8375\n",
      "Epoch 136/200\n",
      "100/100 [==============================] - 97s 970ms/step - loss: 0.0156 - acc: 0.9965 - val_loss: 2.3552 - val_acc: 0.7881\n",
      "Epoch 137/200\n",
      "100/100 [==============================] - 97s 976ms/step - loss: 0.0106 - acc: 0.9969 - val_loss: 2.8243 - val_acc: 0.7906\n",
      "Epoch 138/200\n",
      "100/100 [==============================] - 98s 984ms/step - loss: 0.0168 - acc: 0.9941 - val_loss: 4.3075 - val_acc: 0.6062\n",
      "Epoch 139/200\n",
      "100/100 [==============================] - 98s 985ms/step - loss: 0.0163 - acc: 0.9956 - val_loss: 2.5280 - val_acc: 0.7887\n",
      "Epoch 140/200\n",
      "100/100 [==============================] - 99s 987ms/step - loss: 0.0122 - acc: 0.9966 - val_loss: 3.0236 - val_acc: 0.6869\n",
      "Epoch 141/200\n",
      "100/100 [==============================] - 97s 971ms/step - loss: 0.0110 - acc: 0.9959 - val_loss: 4.0716 - val_acc: 0.6144\n",
      "Epoch 142/200\n",
      "100/100 [==============================] - 99s 990ms/step - loss: 0.0165 - acc: 0.9950 - val_loss: 3.9312 - val_acc: 0.6325\n",
      "Epoch 143/200\n",
      "100/100 [==============================] - 99s 993ms/step - loss: 0.0110 - acc: 0.9962 - val_loss: 4.3247 - val_acc: 0.6944\n",
      "Epoch 144/200\n",
      "100/100 [==============================] - 98s 977ms/step - loss: 0.0146 - acc: 0.9962 - val_loss: 3.3015 - val_acc: 0.6850\n",
      "Epoch 145/200\n",
      "100/100 [==============================] - 98s 978ms/step - loss: 0.0148 - acc: 0.9950 - val_loss: 2.5112 - val_acc: 0.7937\n",
      "Epoch 146/200\n",
      "100/100 [==============================] - 99s 991ms/step - loss: 0.0236 - acc: 0.9916 - val_loss: 3.7913 - val_acc: 0.7225\n",
      "Epoch 147/200\n",
      "100/100 [==============================] - 97s 974ms/step - loss: 0.0163 - acc: 0.9934 - val_loss: 2.4068 - val_acc: 0.7750\n",
      "Epoch 148/200\n",
      "100/100 [==============================] - 97s 968ms/step - loss: 0.0225 - acc: 0.9934 - val_loss: 3.0833 - val_acc: 0.7069\n",
      "Epoch 149/200\n",
      "100/100 [==============================] - 97s 975ms/step - loss: 0.0128 - acc: 0.9953 - val_loss: 3.9257 - val_acc: 0.6506\n",
      "Epoch 150/200\n",
      "100/100 [==============================] - 98s 982ms/step - loss: 0.0124 - acc: 0.9966 - val_loss: 3.5663 - val_acc: 0.7387\n",
      "Epoch 151/200\n",
      "100/100 [==============================] - 97s 975ms/step - loss: 0.0182 - acc: 0.9962 - val_loss: 4.0920 - val_acc: 0.6662\n",
      "Epoch 152/200\n",
      "100/100 [==============================] - 107s 1s/step - loss: 0.0115 - acc: 0.9972 - val_loss: 2.5488 - val_acc: 0.7575\n",
      "Epoch 153/200\n",
      "100/100 [==============================] - 98s 984ms/step - loss: 0.0150 - acc: 0.9947 - val_loss: 3.4314 - val_acc: 0.6662\n",
      "Epoch 154/200\n",
      "100/100 [==============================] - 97s 972ms/step - loss: 0.0141 - acc: 0.9959 - val_loss: 3.7679 - val_acc: 0.6850\n",
      "Epoch 155/200\n",
      "100/100 [==============================] - 98s 985ms/step - loss: 0.0176 - acc: 0.9962 - val_loss: 2.8116 - val_acc: 0.6950\n",
      "Epoch 156/200\n",
      "100/100 [==============================] - 98s 979ms/step - loss: 0.0196 - acc: 0.9966 - val_loss: 3.1524 - val_acc: 0.8256\n",
      "Epoch 157/200\n",
      "100/100 [==============================] - 98s 979ms/step - loss: 0.0140 - acc: 0.9959 - val_loss: 4.4548 - val_acc: 0.6988\n",
      "Epoch 158/200\n",
      "100/100 [==============================] - 100s 997ms/step - loss: 0.0154 - acc: 0.9941 - val_loss: 3.0621 - val_acc: 0.7856\n",
      "Epoch 159/200\n",
      "100/100 [==============================] - 97s 976ms/step - loss: 0.0167 - acc: 0.9956 - val_loss: 2.8183 - val_acc: 0.7819\n",
      "Epoch 160/200\n",
      "100/100 [==============================] - 98s 980ms/step - loss: 0.0113 - acc: 0.9950 - val_loss: 4.4061 - val_acc: 0.6819\n",
      "Epoch 161/200\n",
      "100/100 [==============================] - 98s 978ms/step - loss: 0.0144 - acc: 0.9943 - val_loss: 3.7210 - val_acc: 0.7031\n",
      "Epoch 162/200\n",
      "100/100 [==============================] - 98s 985ms/step - loss: 0.0104 - acc: 0.9962 - val_loss: 3.4321 - val_acc: 0.7138\n",
      "Epoch 163/200\n",
      "100/100 [==============================] - 96s 957ms/step - loss: 0.0209 - acc: 0.9937 - val_loss: 3.3474 - val_acc: 0.6963\n",
      "Epoch 164/200\n",
      "100/100 [==============================] - 98s 979ms/step - loss: 0.0153 - acc: 0.9966 - val_loss: 2.6931 - val_acc: 0.7362\n",
      "Epoch 165/200\n",
      "100/100 [==============================] - 99s 994ms/step - loss: 0.0175 - acc: 0.9953 - val_loss: 2.7687 - val_acc: 0.7250\n",
      "Epoch 166/200\n",
      "100/100 [==============================] - 97s 974ms/step - loss: 0.0126 - acc: 0.9950 - val_loss: 3.0413 - val_acc: 0.7462\n",
      "Epoch 167/200\n",
      "100/100 [==============================] - 97s 975ms/step - loss: 0.0165 - acc: 0.9941 - val_loss: 3.1692 - val_acc: 0.7469\n",
      "Epoch 168/200\n",
      "100/100 [==============================] - 98s 979ms/step - loss: 0.0211 - acc: 0.9956 - val_loss: 3.5227 - val_acc: 0.6881\n",
      "Epoch 169/200\n",
      "100/100 [==============================] - 98s 984ms/step - loss: 0.0115 - acc: 0.9972 - val_loss: 5.6535 - val_acc: 0.4831\n",
      "Epoch 170/200\n",
      "100/100 [==============================] - 98s 980ms/step - loss: 0.0164 - acc: 0.9943 - val_loss: 3.2296 - val_acc: 0.7337\n",
      "Epoch 171/200\n",
      "100/100 [==============================] - 98s 980ms/step - loss: 0.0133 - acc: 0.9965 - val_loss: 2.7216 - val_acc: 0.7744\n",
      "Epoch 172/200\n",
      "100/100 [==============================] - 99s 995ms/step - loss: 0.0123 - acc: 0.9972 - val_loss: 3.6467 - val_acc: 0.7806\n",
      "Epoch 173/200\n",
      "100/100 [==============================] - 100s 999ms/step - loss: 0.0201 - acc: 0.9947 - val_loss: 4.2799 - val_acc: 0.7287\n",
      "Epoch 174/200\n",
      "100/100 [==============================] - 97s 975ms/step - loss: 0.0086 - acc: 0.9978 - val_loss: 3.2541 - val_acc: 0.7919\n",
      "Epoch 175/200\n",
      "100/100 [==============================] - 97s 970ms/step - loss: 0.0152 - acc: 0.9968 - val_loss: 2.8260 - val_acc: 0.7663\n",
      "Epoch 176/200\n",
      "100/100 [==============================] - 99s 992ms/step - loss: 0.0157 - acc: 0.9943 - val_loss: 2.7892 - val_acc: 0.8556\n",
      "Epoch 177/200\n",
      "100/100 [==============================] - 97s 975ms/step - loss: 0.0148 - acc: 0.9969 - val_loss: 2.8196 - val_acc: 0.8256\n",
      "Epoch 178/200\n",
      "100/100 [==============================] - 98s 980ms/step - loss: 0.0092 - acc: 0.9972 - val_loss: 4.1190 - val_acc: 0.6719\n",
      "Epoch 179/200\n",
      "100/100 [==============================] - 97s 976ms/step - loss: 0.0120 - acc: 0.9962 - val_loss: 3.9436 - val_acc: 0.8619\n",
      "Epoch 180/200\n",
      "100/100 [==============================] - 98s 981ms/step - loss: 0.0231 - acc: 0.9934 - val_loss: 4.1669 - val_acc: 0.6581\n",
      "Epoch 181/200\n",
      "100/100 [==============================] - 98s 981ms/step - loss: 0.0172 - acc: 0.9934 - val_loss: 4.4294 - val_acc: 0.6231\n",
      "Epoch 182/200\n",
      "100/100 [==============================] - 98s 980ms/step - loss: 0.0100 - acc: 0.9968 - val_loss: 2.6010 - val_acc: 0.8163\n",
      "Epoch 183/200\n",
      "100/100 [==============================] - 98s 982ms/step - loss: 0.0176 - acc: 0.9941 - val_loss: 3.4472 - val_acc: 0.7362\n",
      "Epoch 184/200\n",
      "100/100 [==============================] - 98s 985ms/step - loss: 0.0082 - acc: 0.9968 - val_loss: 2.3726 - val_acc: 0.7569\n",
      "Epoch 185/200\n",
      "100/100 [==============================] - 98s 986ms/step - loss: 0.0166 - acc: 0.9947 - val_loss: 3.2489 - val_acc: 0.7887\n",
      "Epoch 186/200\n",
      "100/100 [==============================] - 98s 982ms/step - loss: 0.0141 - acc: 0.9953 - val_loss: 3.5626 - val_acc: 0.7475\n",
      "Epoch 187/200\n",
      "100/100 [==============================] - 97s 975ms/step - loss: 0.0115 - acc: 0.9956 - val_loss: 5.2879 - val_acc: 0.7056\n",
      "Epoch 188/200\n",
      "100/100 [==============================] - 97s 974ms/step - loss: 0.0169 - acc: 0.9953 - val_loss: 2.9627 - val_acc: 0.7731\n",
      "Epoch 189/200\n",
      "100/100 [==============================] - 97s 970ms/step - loss: 0.0127 - acc: 0.9962 - val_loss: 5.2135 - val_acc: 0.5481\n",
      "Epoch 190/200\n",
      "100/100 [==============================] - 99s 991ms/step - loss: 0.0185 - acc: 0.9959 - val_loss: 3.8466 - val_acc: 0.6837\n",
      "Epoch 191/200\n",
      "100/100 [==============================] - 97s 970ms/step - loss: 0.0145 - acc: 0.9959 - val_loss: 3.2228 - val_acc: 0.7763\n",
      "Epoch 192/200\n",
      "100/100 [==============================] - 97s 971ms/step - loss: 0.0136 - acc: 0.9953 - val_loss: 4.3929 - val_acc: 0.7769\n",
      "Epoch 193/200\n",
      "100/100 [==============================] - 98s 984ms/step - loss: 0.0134 - acc: 0.9956 - val_loss: 3.2830 - val_acc: 0.8431\n",
      "Epoch 194/200\n",
      "100/100 [==============================] - 96s 960ms/step - loss: 0.0154 - acc: 0.9956 - val_loss: 4.1623 - val_acc: 0.7506\n",
      "Epoch 195/200\n",
      "100/100 [==============================] - 97s 968ms/step - loss: 0.0144 - acc: 0.9966 - val_loss: 3.0842 - val_acc: 0.7981\n",
      "Epoch 196/200\n",
      "100/100 [==============================] - 97s 973ms/step - loss: 0.0147 - acc: 0.9959 - val_loss: 3.5380 - val_acc: 0.7744\n",
      "Epoch 197/200\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.0080 - acc: 0.9978 - val_loss: 4.9107 - val_acc: 0.7356\n",
      "Epoch 198/200\n",
      "100/100 [==============================] - 99s 994ms/step - loss: 0.0178 - acc: 0.9934 - val_loss: 3.4585 - val_acc: 0.7663\n",
      "Epoch 199/200\n",
      "100/100 [==============================] - 99s 991ms/step - loss: 0.0133 - acc: 0.9959 - val_loss: 3.8724 - val_acc: 0.7625\n",
      "Epoch 200/200\n",
      "100/100 [==============================] - 99s 996ms/step - loss: 0.0130 - acc: 0.9962 - val_loss: 3.1438 - val_acc: 0.8175\n"
     ]
    }
   ],
   "source": [
    "samples_per_epoch = 100\n",
    "\n",
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=samples_per_epoch,\n",
    "        epochs = 200,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d3c13f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('AI_only_18.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff5dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label = 'Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label = 'Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'ro', label = 'Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label = 'Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f2c0a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights = 'imagenet',\n",
    "                 include_top = False,\n",
    "                 input_shape=(150, 150, 3))\n",
    "\n",
    "#conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e17af16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               2097408   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 16,812,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation = 'relu'))\n",
    "model.add(layers.Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23bfc8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 38152 images belonging to 2 classes.\n",
      "Found 9042 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        r'C:\\Users\\Seo\\Desktop\\png\\train',\n",
    "        target_size=(150,150),\n",
    "        batch_size = 20,\n",
    "        class_mode = 'binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        r'C:\\Users\\Seo\\Desktop\\png\\test',\n",
    "        target_size=(150,150),\n",
    "        batch_size = 20,\n",
    "        class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4029abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=optimizers.RMSprop(learning_rate=2e-5),\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "361eb338",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seo\\AppData\\Local\\Temp\\ipykernel_13588\\2677506925.py:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 64s 629ms/step - loss: 0.0169 - acc: 0.9945 - val_loss: 0.5872 - val_acc: 0.9000\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.0084 - acc: 0.9980 - val_loss: 0.8811 - val_acc: 0.8760\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 61s 606ms/step - loss: 0.0132 - acc: 0.9955 - val_loss: 0.7859 - val_acc: 0.8950\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 60s 604ms/step - loss: 0.0102 - acc: 0.9970 - val_loss: 0.7230 - val_acc: 0.8850\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 61s 608ms/step - loss: 0.0149 - acc: 0.9970 - val_loss: 0.7791 - val_acc: 0.8970\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 61s 614ms/step - loss: 0.0112 - acc: 0.9975 - val_loss: 0.7156 - val_acc: 0.8930\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 0.0131 - acc: 0.9950 - val_loss: 0.5475 - val_acc: 0.8980\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 64s 639ms/step - loss: 0.0065 - acc: 0.9980 - val_loss: 1.0926 - val_acc: 0.8820\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 0.0027 - acc: 0.9990 - val_loss: 0.9508 - val_acc: 0.8880\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 63s 628ms/step - loss: 0.0122 - acc: 0.9950 - val_loss: 0.7141 - val_acc: 0.9050\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 0.0078 - acc: 0.9965 - val_loss: 0.9536 - val_acc: 0.8900\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 60s 601ms/step - loss: 0.0162 - acc: 0.9960 - val_loss: 1.1457 - val_acc: 0.8790\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 67s 675ms/step - loss: 0.0072 - acc: 0.9975 - val_loss: 0.7051 - val_acc: 0.9060\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 61s 607ms/step - loss: 0.0067 - acc: 0.9980 - val_loss: 0.8803 - val_acc: 0.8880\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 61s 615ms/step - loss: 0.0080 - acc: 0.9970 - val_loss: 0.6910 - val_acc: 0.8960\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 61s 607ms/step - loss: 0.0121 - acc: 0.9955 - val_loss: 0.7842 - val_acc: 0.9080\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 62s 617ms/step - loss: 0.0075 - acc: 0.9975 - val_loss: 1.2521 - val_acc: 0.8770\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 60s 596ms/step - loss: 0.0056 - acc: 0.9975 - val_loss: 0.7019 - val_acc: 0.8950\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 61s 609ms/step - loss: 0.0144 - acc: 0.9960 - val_loss: 0.9954 - val_acc: 0.8770\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 62s 616ms/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.8364 - val_acc: 0.8970\n"
     ]
    }
   ],
   "source": [
    "#나중에는 epochs 30으로 돌리기\n",
    "\n",
    "samples_per_epoch = 100\n",
    "\n",
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=samples_per_epoch,\n",
    "        epochs = 20,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32e98b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label = 'Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label = 'Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'ro', label = 'Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label = 'Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc996bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('vehicles_and_non-vehicles.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08fce618",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(\u001b[43mx_test\u001b[49m, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest loss:\u001b[39m\u001b[38;5;124m'\u001b[39m, test_loss)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest accuracy:\u001b[39m\u001b[38;5;124m'\u001b[39m, test_acc)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba333ef4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conv_base' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mconv_base\u001b[49m\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      3\u001b[0m set_trainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m conv_base\u001b[38;5;241m.\u001b[39mlayers:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'conv_base' is not defined"
     ]
    }
   ],
   "source": [
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98445cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=optimizers.RMSprop(learning_rate = 1e-5),\n",
    "             metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd46560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#나중에는 epochs 30으로 돌리기\n",
    "\n",
    "samples_per_epoch = 100\n",
    "\n",
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=samples_per_epoch,\n",
    "        epochs = 20,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ee25be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label = 'Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label = 'Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'ro', label = 'Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label = 'Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c8fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.8):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1-factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points\n",
    "\n",
    "plt.plot(epochs,\n",
    "        smooth_curve(acc), 'bo', label ='Smoothed training acc')\n",
    "plt.plot(epochs,\n",
    "        smooth_curve(val_acc), 'b', label = 'Smoothed validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs,\n",
    "        smooth_curve(loss), 'ro', label ='Smoothed training loss')\n",
    "plt.plot(epochs,\n",
    "        smooth_curve(val_loss), 'r', label = 'Smoothed validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f1c7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('new_final_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26134e47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b36f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbefb68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
